{
    "description": "Connect to Qualtrics Survey",
    "component": "com.sap.system.python3Operator",
    "versionStatus": "active",
    "outports": [
        {
            "name": "outData",
            "type": "string"
        }
    ],
    "iconsrc": "qualtrics-xm-logo-vector.svg",
    "config": {
        "$type": "http://sap.com/vflow/Connect to Qualtrics Survey.configSchema.json",
        "script": "######## QUALTRICS SURVEY EXTRACTION #######\r\n\r\n# Python 3\r\nimport pandas as pd\r\nimport requests\r\nimport zipfile\r\nimport json\r\nimport io\r\nimport datetime\r\nfrom datetime import datetime\r\nimport time\r\nimport pytz\r\nfrom dateutil import parser\r\n\r\ntz = pytz.timezone('UTC')\r\n\r\n\r\n# Setting user Parameters\r\nrestConn = api.config.qualtrics_connection['connectionProperties']\r\n\r\napiToken = restConn['apiKeyValue']\r\nbody = {}\r\nbody['surveyId'] = api.config.surveyID\r\nbody['format'] = \"csv\"\r\ndataCenter = restConn['host']\r\nstartDate = datetime.strptime(api.config.StartDate, \"%Y-%m-%dT%H:%M\")\r\n\r\n\r\n# Setting static parameters\r\nrequestCheckProgress = 0\r\nprogressStatus = \"in progress\"\r\n#baseUrl = \"https://{0}.qualtrics.com/API/v3/responseexports/\".format(dataCenter)\r\nbaseUrl = \"https://{0}/API/v3/responseexports/\".format(dataCenter)\r\nheaders = {\r\n    \"content-type\": \"application/json\",\r\n    \"x-api-token\": apiToken,\r\n    }\r\n\r\n\r\n\r\nbody['startDate'] = tz.localize(startDate).replace(microsecond=0).isoformat()\r\nbody['endDate'] = tz.localize(datetime.now()).replace(microsecond=0).isoformat()\r\n\r\n# Step 1: Creating Data Export\r\ndownloadRequestUrl = baseUrl\r\ndownloadRequestPayload = json.dumps(body)\r\ndownloadRequestResponse = requests.request(\"POST\", downloadRequestUrl, data=downloadRequestPayload, headers=headers)\r\napi.logger.info(\"Response Check\")\r\napi.logger.info(downloadRequestResponse.text)\r\napi.logger.info(apiToken)\r\nprogressId = downloadRequestResponse.json()[\"result\"][\"id\"]\r\n\r\n# Step 2: Checking on Data Export Progress and waiting until export is ready\r\n\r\nisFile = None\r\n\r\nwhile requestCheckProgress \u003c 100 and progressStatus is not \"complete\" and isFile is None:\r\n    requestCheckUrl = baseUrl + progressId\r\n    requestCheckResponse = requests.request(\"GET\", requestCheckUrl, headers=headers)\r\n    isFile = (requestCheckResponse.json()[\"result\"][\"file\"])\r\n    if isFile is None:\r\n        api.logger.info(\"file not ready\")\r\n    else:\r\n        api.logger.info(\"file created:\", requestCheckResponse.json()[\"result\"][\"file\"])\r\n        requestCheckProgress = requestCheckResponse.json()[\"result\"][\"percentComplete\"]\r\n        api.logger.info(\"Download is \" + str(requestCheckProgress) + \" complete\")\r\n\r\n# Step 3: Downloading file\r\nrequestDownloadUrl = baseUrl + progressId + '/file'\r\nheaders = {\r\n    \"X-Requested-With\": 'XMLHttpRequest',\r\n    \"content-type\": \"application/zip\",\r\n    \"x-api-token\": apiToken,\r\n    }\r\nrequestDownload = requests.request(\"GET\", requestDownloadUrl, headers=headers, stream=True)\r\nresponse_code = requestDownload.status_code\r\nif response_code != 200:\r\n    api.logger.info(\"Unsuccessful request with code {}. Response: {}\".format(response_code, requestDownload.text))\r\n\r\n# Step 4: Unzipping the file and convert to Pandas dataframe\r\nresponsesZip = zipfile.ZipFile(io.BytesIO(requestDownload.content))\r\n\r\n# Step 5 Converting to Pandas dataframe\r\ndfs=[]\r\nfor file in responsesZip.namelist():\r\n  dfs.append(pd.read_csv(responsesZip.open(file),sep=','))\r\ndf1 = pd.concat(dfs)\r\n\r\n\r\n# Step 6 data cleansing and transformation: \r\n# remove rows and columns (manually, different from survey to survey)\r\ndf1 = df1.drop([0, 1])\r\ndf1 = df1.drop(['ResponseSet','IPAddress','StartDate','ExternalDataReference','Finished','Status','LocationLatitude','LocationLongitude','LocationAccuracy'], axis=1)\r\ndf1 = df1.drop(['TicketID','Category','Subtype','Priority','Date','RequestorCategory','Channel','Create New Field or Choose From Dropdown...','Q0','Q10_1_TEXT','Q10_2_TEXT','Q10_3_TEXT','Q10_4_TEXT','Q10_5_TEXT','Q10_6_TEXT','Q10_7_TEXT','Q8'], axis=1)\r\n\r\n# convert timestamp into milliseconds (not supported now in ingestion API) for all timestamp columns\r\ndf1['EndDate'] = df1['EndDate'].apply(lambda x:  round(parser.parse(x).timestamp() * 1000))\r\n\r\n# convert into string for all string columns (from object type)\r\ndf1['ResponseID'] = df1['ResponseID'].apply(lambda x:  str(x))\r\ndf1['RecipientLastName'] = df1['RecipientLastName'].apply(lambda x:  str(x))\r\ndf1['RecipientFirstName'] = df1['RecipientFirstName'].apply(lambda x:  str(x))\r\ndf1['RecipientEmail'] = df1['RecipientEmail'].apply(lambda x:  str(x))\r\ndf1['Location'] = df1['Location'].apply(lambda x:  str(x))\r\ndf1['Type'] = df1['Type'].apply(lambda x:  str(x))\r\ndf1['Operator'] = df1['Operator'].apply(lambda x:  str(x))\r\n\r\n# convert into float for all float columns (from object type)\r\ndf1['Q1'] = df1['Q1'].apply(lambda x:  float(x))\r\ndf1['Q5_1'] = df1['Q5_1'].apply(lambda x:  float(x))\r\ndf1['Q5_2'] = df1['Q5_2'].apply(lambda x:  float(x))\r\ndf1['Q5_3'] = df1['Q5_3'].apply(lambda x:  float(x))\r\ndf1['Q11_1'] = df1['Q11_1'].apply(lambda x:  float(x))\r\ndf1['Q11_2'] = df1['Q11_2'].apply(lambda x:  float(x))\r\ndf1['Q11_3'] = df1['Q11_3'].apply(lambda x:  float(x))\r\ndf1['Q6'] = df1['Q6'].apply(lambda x:  float(x))\r\n\r\n# replace null values with blank\r\ndf1.fillna(\"\", inplace = True)\r\n\r\n\r\n# Step 7 write locally file csv\r\ndf1_csv = df1.to_csv(index=False)\r\n\r\napi.send(\"outData\", df1_csv)\r\n"
    }
}
